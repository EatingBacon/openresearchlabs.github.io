---
layout: page
title: "TKO_3121: Topics"
author: Leo Lahti
date: Spring 2020
permalink: /edu/tko3121
---

========


# Machine Learning and Algorithmics Seminar 2020

## Proposed seminar topics

### Session 1: Introduction

- Participants
- Overview and practicalities
- Assigning the topics

### Session 2 Position papers 

McElreath, R., & Smaldino, P. E. (2015). Replication, Communication, and the Population Dynamics of Scientific Discovery. 
Rahwan, I., Cebrian, M., Obradovich, N., Bongard, J., Bonnefon, J., & Breazeal, C., et al. (2019). Machine behaviour. 
Beyond subjective and objective in statistics (with discussion and rejoinder). Journal of the Royal Statistical Society A 180, 967--1033. Andrew Gelman and Christian Hennig (2017).

Session 3 Hypothesis testing and significance
[2019] Abandon statistical significance. {\em American Statistician} {\bf 73} (S1), 235--245. (Blakeley B. McShane, David Gal, Andrew Gelman, Christian Robert, and Jennifer L. Tackett) 
The ASA Statement on p-Values: Context, Process, and Purpose. Ronald L. Wasserstein & Nicole A. Lazar. Pages 129-133 | Accepted author version posted online: 07 Mar 2016, Published online:09 Jun 2016 https://doi.org/10.1080/00031305.2016.1154108
Bayesian statistics Jorge López Puga, Martin Krzywinski & Naomi Altman  Nature Methods volume 12, pages377–378(2015)
Jaynes, E. T., 1976. `Confidence Intervals vs Bayesian Intervals,' in Foundations of Probability Theory, Statistical Inference, and Statistical Theories of Science, W. L. Harper and C. A. Hooker (eds.), D. Reidel, Dordrecht, p. 175; https://bayes.wustl.edu/etj/articles/confidence.pdf

Session 4 Prior information
[2017] The prior can often only be understood in the context of the likelihood. {\em Entropy} {\bf 19}, 555. (Andrew Gelman, Daniel Simpson, and Michael Betancourt) 
[2019] The experiment is just as important as the likelihood in understanding the prior: A cautionary note on robust cognitive modelling. {\em Computational Brain and Behavior}. (Lauren Kennedy, Daniel Simpson, and Andrew Gelman)
Juho Piironen and Aki Vehtari (2017). Sparsity information and regularization in the horseshoe and other shrinkage priors. In Electronic Journal of Statistics, 11(2):5018-5051. Online. arXiv preprint arXiv:1707.01694. After the article was published, the regularized horseshoe prior has been implemented in rstanarm and brms (but without conditioning on sigma). 

Session 5 Visualization
UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. Leland McInnes, John Healy, James Melville (2018)
Tipping, M. E., & Bishop, C. M. (1999). Probabilistic principal component analysis. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611–622.
Lan Huong Nguyen and Susan Holmes (2017) Bayesian Unidimensional Scaling for visualizing uncertainty in high dimensional datasets with latent ordering of observations. BMC Bioinformatics, August, 2017. [BMC journal link] 

Session 6 Feature selection
Tianqi Chen and Carlos Guestrin. XGBoost: A Scalable Tree Boosting System. In 22nd SIGKDD Conference on Knowledge Discovery and Data Mining, 2016. https://arxiv.org/abs/1603.02754
Juho Piironen, Markus Paasiniemi, and Aki Vehtari (2018). Projective inference in high-dimensional problems: prediction and feature selection. arXiv preprint arXiv:1810.02406. Code. 
Michael Riis Andersen, Aki Vehtari, Ole Winther and Lars Kai Hansen (2017). Bayesian inference for spatio-temporal spike and slab priors. In Journal of Machine Learning Research, 18(139):1-58, Online. arXiv preprint arXiv:1509.04752. 

Session 7 Model selection
Bayesian model selection for complex dynamic systems Christoph Mark, Claus Metzner, Lena Lautscham, Pamela L. Strissel, Reiner Strick, Ben Fabry. Nature Communications volume 9(1803), 2018
Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. In Statistics and Computing, 27(5):1413–1432. doi:10.1007/s11222-016-9696-4. Online. arXiv preprint arXiv:1507.04544. Matlab code. Python code. R code. 
Juho Piironen and Aki Vehtari (2017). Comparison of Bayesian predictive methods for model selection. Statistics and Computing, 27(3):711-735. doi:10.1007/s11222-016-9649-y. First Online 07 April 2016. arXiv preprint arXiv:1503.08650. Supplement: Juho Piironen and Aki Vehtari (2015). Projection predictive variable selection using Stan+R. arXiv preprint arXiv:1508.02502. Code

Session 8 Scalable inference
Automatic variational inference in Stan. Neural Information Processing Systems. Alp Kucukelbir, Rajesh Ranganath, Andrew Gelman, and David Blei. 2015
Lintusaari, Jarno; Gutmann, Michael U.; Dutta, Ritabrata; Kaski, Samuel & Corander, Jukka (2017). Fundamentals and recent developments in approximate Bayesian computation. Systematic Biology.  ISSN 1063-5157.  66(1), s e66- e82 . doi: 10.1093/sysbio/syw077
Bayesian Computing with INLA: A Review. Håvard Rue, Andrea Riebler, Sigrunn H. Sørbye, Janine B. Illian, Daniel P. Simpson, Finn K. Lindgren. https://arxiv.org/abs/1604.00860
Expectation propagation as a way of life: A framework for Bayesian inference on partitioned data. Journal of Machine Learning Research. 21, 1--53. (Aki Vehtari, Andrew Gelman, Tuomas Sivula, Pasi Jylanki, Dustin Tran, Swupnil Sahai, Paul Blomstedt, John P. Cunningham, David Schiminovich, and Christian P. Robert [2020] 
A Conceptual Introduction to Hamiltonian Monte Carlo. Michael Betancourt. arXiv:1701.02434 [pdf, other] 

Session 10 Time series
Lu Cheng, Siddharth Ramchandran, Tommi Vatanen, Niina Lietzen, Riitta Lahesmaa, Aki Vehtari, and Harri Lähdesmäki (2019). LonGP: an additive Gaussian process regression model for longitudinal study designs. Nature Communications, 10:1798. Online. bioRxiv preprint. 
Juho Timonen, Henrik Mannerström, Aki Vehtari, Harri Lähdesmäki (2019). An interpretable probabilistic machine learning method for heterogeneous longitudinal studies. arXiv preprint arXiv:1912.03549. lgpr software package.
Unifying Probabilistic Models for Time-frequency Analysis WJ Wilkinson, MR Andersen, JD Reiss, D Stowell, A Solin. ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and …
Filip Tronarp, Hans Kersting, Simo Särkkä, Philipp Hennig (2019). Probabilistic Solutions To Ordinary Differential Equations As Non-Linear Bayesian Filtering: A New Perspective. Accepted for publication in Statistics and Computing. (arXiv) 
Bayesian Survival Analysis Using the rstanarm R Package. Samuel L. Brilleman (1), Eren M. Elci (2), Jacqueline Buros Novik (3), Rory Wolfe
A hierarchical Ornstein-Uhlenbeck model for stochastic time series analysis. In: Ville Laitinen and Leo Lahti. Advances in Intelligent Data Analysis XVII. Lecture Notes in Computer Science 11191., Springer, India, 2018. Conference proceedings. https://openresearchlabs.github.io/publications/papers/2018-Laitinen-IDA.pdf

Session 11 Gaussian processes
Marko Järvenpää, Michael Gutmann, Aki Vehtari and Pekka Marttinen (2018). Gaussian process modeling in approximate Bayesian computation to estimate horizontal gene transfer in bacteria. The Annals of Applied Statistics, 12(4):2228-2251. Online. arXiv preprint arXiv:1610.06462. 
Additive multivariate Gaussian processes for joint species distribution modeling with heterogeneous data. J Vanhatalo, M Hartmann, L Veneranta. Bayesian Analysis
Laplace approximation and natural gradient for Gaussian process regression with heteroscedastic student-t model M Hartmann, J Vanhatalo. Statistics and Computing 29 (4), 753-773
Deep Gaussian Processes. Andreas C. Damianou, Neil D. Lawrence. https://arxiv.org/abs/1211.0358
Boettiger C, Mangel M, Munch S. Avoiding tipping points in fisheries management through Gaussian process dynamic programming. Proc Biol Sci. 2015;282(1801):20141631. doi:10.1098/rspb.2014.1631

Session 12 Bayesian workflow
Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society Series A, 182(2):389-402. Online. arXiv preprint arXiv:1709.01449. Discussion and rejoinder. 
Toward a principled Bayesian workflow in cognitive science. Daniel J. Schad, Michael Betancourt, Shravan Vasishth. https://arxiv.org/abs/1904.12765
Validating  Bayesian  Inference Algorithms  with  Simulation-Based Calibration. Sean Talts, Michael Betancourt, Daniel Simpson, Aki Vehtari, Andrew Gelman. https://arxiv.org/pdf/1804.06788.pdf
Jarno Lintusaari, Henri Vuollekoski, Antti Kangasrääsiö, Kusti Skytén, Marko Järvenpää, Michael Gutmann, Aki Vehtari, Jukka Corander, and Samuel Kaski (2018). ELFI: Engine for Likelihood Free Inference. In Journal of Machine Learning Research, 19(16):1-7, 2018. arXiv preprint arXiv:1708.00707

Session 13 Deep learning, neural nets, and autoencoders
Learning representations of microbe–metabolite interactions. JT Morton, AA Aksenov, LF Nothias, JR Foulds, RA Quinn, MH Badri, … Nature methods 16 (12), 1306-1314
An Introduction to Variational Autoencoders. Diederik P. Kingma, Max Welling. https://arxiv.org/abs/1906.02691
Bayesian GAN. Yunus Saatchi, Andrew Gordon Wilson. https://arxiv.org/abs/1705.09558
Deep Learning: A Bayesian Perspective. Nicholas Polson, Vadim Sokolov. https://arxiv.org/abs/1706.00473
Towards Bayesian Deep Learning: A Survey. Hao Wang, Dit-Yan Yeung. https://arxiv.org/abs/1604.01662

Session 14 Applications
Julia Fukuyama , Laurie Rumker , Kris Sankaran , Pratheepa Jeganathan, Les Dethlefsen, David A. Relman , Susan P. Holmes (2017) Multidomain analyses of a longitudinal human microbiome intestinal cleanout perturbation experiment. PLOS Computational Biology, August 2017. [Plos Comp Bio Link] 
Tonkin-Hill, Gerry; Lees, John A; Bentley, Stephen D; Frost, Simon DW & Corander, Jukka (2019). Fast hierarchical Bayesian analysis of population structure. Nucleic Acids Research.  ISSN 0305-1048.  47(11), s 5539- 5549 . doi: 10.1093/nar/gkz361
Additive multivariate Gaussian processes for joint species distribution modeling with heterogeneous data. Jarno Vanhatalo†, Marcelo Hartmann‡and Lari Veneranta. Bayesian analysis 2019. https://arxiv.org/pdf/1809.02432.pdf

Session 15 Wrap-up



